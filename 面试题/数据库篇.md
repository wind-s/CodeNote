数据库篇：

    1.mybatis. innDb的一些特性， 周阳的视频讲的不错，刷起来。
    2.mysql,  无索引，索引找不到，也就是输入的东西不能通过索引获取，行锁变表锁，其他mysql操作会阻塞。
    3.mysql 间隙锁，query是通过范围查找，会锁定这个区域内的所有索引键值，即使这个简直不存在，这个时候就不能插入间隙值了。
        间隙锁：当我们用范围条件而不是相等条件检索数据时，并请求共享或拍他锁时，InnoDB会给符合条件的已有数据的索引项加锁，
                对于键值在条件范围内但不存在的记录，叫做间隙，innoDb也会对这个间隙加锁。
        危害：某些不存在的键值被锁定，无法插入键值范围内的任何数据。
    4.如何分析InnoDb行锁定：

    show status like '%innodb_row_lock%'; 获取状态变量分析系统上的行锁的争夺情况。

    innodb_row_lock_current_waits: 当前正在等待锁定的数量；
    innodb_row_lock_time_max: 时间最长的一次所花时间；
    innodb_row_lock_time: 从系统启动到现在锁定总时间长度 ；
    innodb_row_lock_time_avg: 每次等待所花的平均时间；
    innodb_row_lock_waits:  系统启动后到现在总等待次数；

    5.数据库行锁优化建议：
        1.尽可能让所有数据检索都是通过索引完成的，避免无索引行锁升级为表锁
        2.合理设计索引，尽量缩小缩的范围
        3.尽可能较少的检索条件，避免间隙锁
        4.尽量控制事务大小，减少锁定资源量的时间长度
        5.尽可能低级别事务隔离
    6.页锁，介于表锁，行锁之间，会出现死锁，并发度一般。
《MySQL 45讲》

    7.事务的ACID属性
    1.原子性
        要么全部执行，要么都不执行
    2.一致性
        事务开始和完成时，数据都必须保持一致状态。
    3.隔离性
        事务不受外部并发操作影响，事务处理过程的中间状态不可见。
    4.持久性
        事务完成后，数据的修改时永久性的。


    7.行锁支持事务。但是并发事务处理也会带来问题
    1.更新丢失：多个事务基于最初选定的值就行更新该行，由于事务不可见，最后会覆盖结果。 
    2.脏读：事务a对某记录做修改，但是未提交，数据处于不一致，此时，该数据被事务b读取。 已提交读级别 解决，不能解决不可重复读，幻读。
    3.不可重复读： 事务读取某个数据后，再次读取，发现数据被修改，不可重复读。 可重复读级别解决
    4.幻读：事务在插入已经检查过不存在的记录时，惊奇的发现这些数据已经存在了，之前的检测获取到的数据如同鬼影一般。比如全表数值更新，结果又被人插入记录，与最初获取的数据不一致。 串行化可解决，牺牲大。

    8.数据库多版本并发控制
    1.mvcc, 多版本并发控制, innodb的实现是基于多版本并发控制协议（mvcc）
        http://hedengcheng.com/?p=771#_Toc374698307
        https://juejin.im/post/5c68a4056fb9a049e063e0ab
        读、写事务相互隔离，不需要加锁。读写并存的时候，写操作会根据目前数据库的状态，创建一个新版本，并发的读则依旧访问旧版本的数据。
        MVCC(Multiversion concurrency control) 就是 同一份数据临时保留多版本的一种方式，进而实现并发控制.

    2.SELECT @@tx_isolation; 查看数据库的隔离事务。

    3.数据库在测试事务的时候，需要关掉数据库的自动提交， set session autocommit=off;

    4.begin,开始事务，sql, commit. 不提交的话就会被锁住，其他session  访问可能就得等待了。

    5.一个事务未进行 commit/rollback操作之前，另一个事务仍然可以读取到数据库中的数据，只不过是读取到的是其他事务未改变之前的数据。此处是利用了MVCC多数据做了多版本处理，读取的数据来源于快照。

    https://mp.weixin.qq.com/s/_YNVH0cjIcHjtoVcswBkIA
    6.redo log 通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)

    7.undo 用来回滚行记录到某个版本。undo log 一般是逻辑日志，根据每行记录进行记录

    9.mysql存储引擎有哪些？有什么区别
    1.myISam
        优点：
            1.高性能读取。
            2.保存了表的行数，使用 count不会扫描全表。
        缺点：
            1.不支持数据库事务。
            2.不支持行锁，外键，表锁。
            3.insert, update需要锁定整个表。
            4.不支持故障恢复。

         场景：
            1.不需要事务操作。
            2。插入更新少，读取频繁。
            3.频繁统计计算。
    2.innodb
        优点：
            1.支持事务处理，acid特性
            2.实现sql标准的四种隔离级别
            3.支持行锁和外键约束
            4.利用事务日志进行数据恢复
        缺点：
            1.不保存表的行数，count会扫描全表。
        场景：
            1.需要事务的操作；
            2.更新数据需要使用行级锁；
            3.大数据量读写；
            4.大型互联网应用。

    10.mysql索引什么时候会失效？
    奇葩的写法就会失效，例如：
    1.最佳左前缀法则——如果索引了多列，要遵守最左前缀法则。指的是查询要从索引的最左前列开始并且不跳过索引中的列。违反了最佳左前缀法则，导致索引失效，变为ALL,全表扫描。
    2.当用函数操作加的索引列时，索引将会失效，变成了全表扫描
    3.存储引擎不能使用索引中范围条件右边的列。——范围之后索引失效。（< ,> between and,）age>5, 那么后续的索引就会失效。
    4.MYSQL使用不等于（<,>,!=）的时候无法使用索引，会导致索引失效
    5.like以通配符开头（'%abc...'）MYSQL索引失效会变成全表扫描的操作
    6.is null或者is not null 也会导致无法使用索引。
    7.字符串不加单引号索引失效
    8.少用or，用它来连接时索引会失效。

    11.mysql 的索引模型？
    索引是数据结构，排好序的快速查找结构。存储于磁盘中
    平时使用的索引默认都是b+树索引。
    模型就是一个查找树。

    索引结构：
        1.B+树索引,重点，检索原理
            三节点索引树，叶子节点存储数据，非叶子结点存储指引索引方向的数据项指针。
            整个b+树由很多数据项组成，数据项又由指针，组成，每次检索，就是把磁盘中的数据块二分查找，加载到内存中，进行判断。

         3层的b+树，可以表示上百万的数据，1700000+，只发生了三次io.
        数据越相同，效率越低，反之亦然。越不同，效率越高。
        2.hash索引
        3.全文索引
        4.R树索引

    12.mysql 主从同步怎么搞的？分哪几个过程？如果有一台新机器要加到从机里，怎么个过程。
    mysql复制三步：
        1.master将改变的记录到binary log, 二进制日志事件。
        2.slave将master的 binary log event拷贝到他的中继日志（relay log）
        3.slave重做中继日志中的事件，将改变应用到自己的数据库中，mysql复制是异步，串行化的。
    从机扩容：
        1.主机配置。
        2.从机器配置。
        3.主机创建同步账号。
        4.从机设置同步主机。
        5.开启同步。

    详细过程：
        1.主机配置 server_id=1 主服务器唯一id，启动binary log日志
        2.从机 vi /etc/my.cnf 开启二进制日志log-bin 
        3.修改server_id=2，下一台就是server_id=3 , read-only=1
        4.因修改过配置，重启从机服务器。service mysql stop/start
        5.在主机执行分配权限命令， grant replication slave on *.* to 'zhangsan'@'从机ip' identified by '123456';
        6.show master status, 查看主机状态 记录下file， position信息
        7.在从机上执行，change master to maser_host='', master_user='',master_password='', master_log_file='file信息（mysqlbin.2323）', master_log_pos=具体值。
        8.从机， start slave
        9.show slave status 查看slave_io_runnning:yes slave_sql_running:yes, 同步成功。
    停止从机复制：
        stop slave

    13.MySQL 事务的四个隔离级别？ 先说了四个级别的区别，然后说了每个级别可能产生的问题
    1.更新丢失：多个事务基于最初选定的值就行更新该行，由于事务不可见，最后会覆盖结果。 
    2.脏读：事务a对某记录做修改，但是未提交，数据处于不一致，此时，该数据被事务b读取。 已提交读级别 解决，不能解决不可重复读，幻读。
    3.不可重复读： 事务读取某个数据后，再次读取，发现数据被修改，不可重复读。 可重复读级别解决
    4.幻读：事务在插入已经检查过不存在的记录时，惊奇的发现这些数据已经存在了，之前的检测获取到的数据如同鬼影一般。比如全表数值更新，结果又被人插入记录，与最初获取的数据不一致。 串行化可解决，牺牲大。

    隔离级别                            更新丢失            脏读              不可重复读                   幻读
    Read Uncommitted（读取未提交内容）    是                 是                是                          是
    Read Committed（读取提交内容）        否                 否                是                          是
    Repeatable Read（可重读）            否                 否                 否                         是
    Serializable（可串行化）              否                 否                 否                        否

    14.binlog 日志和 redolog 日志清楚吗？ 说了两个日志的作用以及两阶段提交？
    https://cloud.tencent.com/developer/article/1067441
    MySQL中有六种日志文件：
        1.重做日志（redo log）
            1.作用：
                确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。
            2.内容：
                物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。
            3.开始时间：
                事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。
            4.结束时间：
                当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。
        2.回滚日志（undo log）
            1.作用：
               保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。 
            2.内容：
                逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。
            3.产生：
                事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性。
            4.释放：
                当事务提交之后，undo log并不能立马被删除，
                而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。
        3.二进制日志（binlog）
            1.作用：
                1.用于复制，主从复制中，从库利用主库上的binlog进行重播，实现主从同步。
                2.用于数据库的基于时间点的还原。
            2.内容：
                逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。
                但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息，
                也就意味着delete对应着delete本身和其反向的insert；
                update对应着update执行前后的版本的信息；
                insert对应着delete和insert本身的信息。
                在使用mysqlbinlog解析binlog之后一些都会真相大白。
                因此可以基于binlog做到类似于oracle的闪回功能，其实都是依赖于binlog中的日志记录。
            3.产生：
                事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。
                因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。
            4.释放：
                binlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。
        4.错误日志（errorlog）
        5.慢查询日志（slow query log）
        6.一般查询日志（general log）
        中继日志（relay log）

    15.explain执行计划
    
mybatis：
    
    1.一级缓存和二级缓存？
    1，一级缓存是SqlSession级别的缓存。在操作数据库时需要构造sqlSession对象，在对象中有一个数据结构（HashMap）用于存储缓存数据。不同的sqlSession之间的缓存数据区域（HashMap）是互相不影响的。如果中间sqlSession去执行commit操作（执行插入、更新、删除），则会清空SqlSession中的一级缓存，这样做的目的为了让缓存中存储的是最新的信息，避免脏读。个人认为一级缓存不是线程安全的，对于同一行数据，另外一个线程写入数据（不使用mybatis组件），会导致session数据无法正常更新。
    2，二级缓存是mapper级别的缓存，多个SqlSession去操作同一个Mapper的sql语句，多个SqlSession可以共用二级缓存，二级缓存是跨SqlSession的。
    3，二级缓存默认是不开启的。

    2.mybatis中#{}和${}的区别?
    #{}把传入的数据当成字符串，加上双引号。防止sql注入
    $将传入的数据直接显示生成在sql中（无法防止sql注入）。
